# 语言模型发展历程（4个阶段）
#语言模型的发展历程
## 统计语言模型（Statistical Language Model, SLM）

### 马尔可夫假设（Markov Assumption）

- 根据词序列中==若干个连续的上下文单词==来预测下一个词的出现概率，即根据一个==固定长度的前缀==来预测目标单词。

-  具有固定上下文长度 𝑛 的统计语言模型通常被称为 𝑛 元 （𝑛-gram）语言模型

- “维数灾难”（Curse of Dimensionality）：对于高阶统计语言模型来说，随着阶数 𝑛 的增加，需要估计的==转移概率项数==将会指数级增长
### 退估计（Back-off Estimation）和古德-图灵估计（Good-Turing Estimation

- 为了缓解数据稀疏问题，所设计专门的语言模型平滑策略

- 对于高阶上下文的刻画能力仍然较弱，无法精确建模复杂的高阶语义关系

## 神经语言模型（Neural Language Model, NLM）

## 预训练语言模型（Pre-trained Language Model, PLM）

- 预训练语言模型在训练架构与训练数据两个方面进行了改进与创新

- ELMo [11] 是一个早期的代表性预训练语言模型，提出使用大量的无标注数据训练双向 LSTM （Bidirectional LSTM, biLSTM）网络，预训练完成后所得到的 biLSTM 可以用来学习上下文感知的单词表示

- 传统序列神经网络的长文本建模能力较弱，并且不容易并行训练，这些缺点限制了早期预训练模型（如 ELMo）的性能

-  Transformer 架构：基于自注意力机制（Self-Attention），对于硬件非常友好，可以通过 GPU 或者 TPU 进行加速训练，这为研发大语言模型提供了可并行优化的神经网络架构

## 大语言模型（Large Language Model, LLM）
- “扩展法则”（Scaling Law）：通过规模扩展 （如增加模型参数规模或数据规模）通常会带来下游任务的模型性能提升

- GPT-3 可以通过“上下文学习”（In-Context Learning, ICL）的方式来利用少样本数据解决下游任务

- 学术界将这些大型预训练语言模型命名为“大语言模型”1 （Large Language Model, LLM）

## 总结
- 首先，早期的统计语言模型主要被用于（或辅助用于）解决一些特定任务，主要以信息检索、文本分类、语音识别等传统任务为主。随后，神经语言模型专注于学习任务无关的语义表征，旨在减少人类特征工程的工作量，可以大范围扩展语言模型可应用的任务。进一步，预训练语言模型加强了语义表征的上下文感知能力，并且可以通过下游任务进行微调，能够有效提升下游任务（主要局限于自然语言处理任务）的性能。随着模型参数、训练数据、计算算力的大规模扩展，最新一代大语言模型的任务求解能力有了显著提升，能够不再依靠下游任务数据的微调进行通用任务的求解。

-----------------------------------------------------------------------------------
# 大语言模型的能力特点
#语言模型的发展历程
- 具有较为丰富的世界知识：大语言模型经过超大规模文本数据的预训练后能够学习到较为丰富的世界知识

- 具有较强的通用任务解决能力（通用性）：大语言模型第二个代表性的能力特点是具有较强的通用任务求解能力，基于大规模无标注文本的下一个词元预测任务本质上可以看作一个多任务学习过程

- 具有较好的复杂任务推理能力


-  具有较强的人类指令遵循能力：大语言模型建立了自然语言形式的统一任务解决模式：任务输入与执行结果均通过自然语言进行表达

- 具有较好的人类对齐能力：通过强化学习使得模型进行正确行为的加强以及错误行为的规避，进而建立较好的人类对齐能力。目前很多线上部署的大语言模型应用，都能够有效阻止典型的模型功能滥用行为，一定程度上规避了常见的使用风险

- 具有可拓展的工具使用能力：工具学习实际上就是借鉴了这一思路，通过具有特殊功能的工具来加强大语言模型的能力

-----------------------------------------------------------------------------------

# 大语言模型关键技术概览
#大语言模型关键技术概览
- 规模扩展：OpenAI 从参数、数据、算力三个方面深入地研究了规模扩展对于模型性能所带来的影响，建立了定量的函数关系，称之为“扩展法则”（Scaling Law）

- 数据工程：首先，需要对于数据进行全面的采集，拓宽高质量的数据来源；其次，需要对于收集到的数据进行精细的清洗，尽量提升用于大模型训练的数据质量；第三，需要设计有效的数据配比与数据课程，加强模型对于数据语义信息的利用效率。

- 高效预训练：由于参数规模巨大，需要使用大规模分布式训练算法优化大语言模型的神经网络参数。在训练过程中，需要联合使用各种并行策略以及效率优化方法，包括 3D 并行（数据并行、流水线并行、张量并行）、ZeRO（内存冗余消除技术）等。其中具有代表性的分布式训练软件包括 DeepSpeed [26] 和 Megatron-LM [27]。

- 能力激发：为了提升模型的任务求解能力，需要设计合适的指令微调以及提示策略进行激发或诱导。在指令微调方面， 可以使用自然语言表达的任务描述以及期望的任务输出对于大语言模型进行指令微调，从而增强大语言模型的通用任务求解能力，提升模型在未见任务上的泛化能力。在提示学习方面，需要设计合适的提示策略去诱导大语言模型生成正确的问题答案。为此，研究人员提出了多种高级提示策略，包括上下文学习、思维链提示等，通过构建特殊的提示模板或者表述形式来提升大语言模型对于复杂任务的求解能力。提示工程已经成为利用大语言模型能力的一个重要技术途径。

- 人类对齐：目前，比较具有代表性的对齐标准是“3 H 对齐标准”，即 Helpfulness（有用性）、Honesty（诚实性）和 Harmlessness（无害性）。OpenAI 提出了基于人类反馈的强化学习算法（Reinforcement Learning from Human Feedback, RLHF）[28]首先训练能够区分模型输出质量好坏的奖励模型，进而使用强化学习算法来指导语言模型输出行为的调整，让大语言模型能够生成符合人类预期的输出。

-  工具使用：通过让大语言模型学会使用各种工具的调用方式，进而利用合适的工具去实现特定的功能需求。工具调用能力主要是通过指令微调以及提示学习两种途径实现，而未经历过特殊训练或者缺乏有效提示的大语言模型则很难有效利用候选工具。

-----------------


