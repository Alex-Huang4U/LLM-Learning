- ###### 操作：
	使用自然语言形式的数据对预训练后的大 语言模型进行参数微调
- ###### 目标：
	使大模型获得较好的指令跟随能力

--------

## 指令数据构建方法

#### 1.基于现有的NPL（Nature Language Processing）任务数据集构建（如翻译等日常任务）
- 给予大模型“输入-输出”对数据，以及增加上任务描述信息，便可进行指令微调，大模型通过这种方式可以学习到指令遵循能力，进而能够解决其他未见过的NPL任务。其中尤为重要的是，添加适合的任务描述信息是提升大模型指令跟随能力的关键。

#### 2.基于日常对话的数据构建
- 目标：
	为了更好地与人类对齐，使用真实的用户查询非常有助于提升大模型的指令跟随能力
- 操作：
	使用用户在日常对话中的实际需求作为任务描述

#### 3.基于合成数据构建（使用大模型等生成工具生成相关指令实例）
- 操作：通过人工书写的实例作为初始任务池，随机选择数据作为示例，提示大模型生成新的指令实例，生成的实例经过筛选后也进入任务池
- 经典的数据合成技术：
	1.Self-Instruct
		首先建立一个初始任务池，从任务池中选择少量示例，并根据设计好的要求生成出新的微调数据，最后对数据进行过滤与后处理，将低质量或者重复的生成实例剔除
	2.Evol-Instruct
		该法是一种基于大语言模型的指令数据复杂化技术，首先将需要处理的基础指令进行指令烟花，大模型作为指令演化器，针对深度和广度进行演化，深度通过物种特定类型的提示（添加约束、深化、具体化、增加推理步骤以及使输入复杂化）使得指令变得 更加复杂与困难；广度演化旨在扩充指令主题范围、指令涉及的能力范围以及 整体数据集的多样性。最后与self-instruct相同进行数据后处理，将一些低质量的指令进行剔除

-----------------------

## 指令数据构建的提升方法
- 在指令微调中，指令数据的格式、数量等因素对微调后的大模型性能有着重要的影响。主要将从指令格式设计、拓展指令数量、指令重写与筛选入手构建高质量数据集

### 指令格式设计
- 标准格式：输入-输出对以及任务描述，其中任务描述是大模型理解任务的关键部分
- 可以增加实例作为上下文示例作为输入，提升模型性能
- 实验表明，使用带少量示例的指令数据混合不带示例的指令数据这种混合提示的训练方式有助于改善下游任务中少样本和零样本的测试效果。
- 为了激发大模型的逐步推理能力，研究人员还在指令微调数据集中引入了思维链数据

### 拓展指令数量
- 通过逐步将指令数量扩展至 0.18M、5.55M、7.2M 以及 17.26M，研究人员发现模型性能呈持续上升的趋势。然而，当指令数量达到 7.2M 后，模型性能的提升变得非常缓慢
- 实际上，对于一个较好的预训练基座模型，越来越多的研究工作表明一定数 量的高质量指令就可以激活大语言模型的对话能力

### 指令重写与筛选

- 研究人员尝试从大量数据集中筛选出部分指令来进行微调。Alpa- gasus 利用 GPT-4 从原始的 52K 条 Alpaca 数据中筛选出 GPT-4 评分较高的 9 千条。 使用这 9 千条数据进行指令微调训练，便可以在下游测试任务中达到与原始 52K 条数据接近的效果。
- YuLan-Chat-3 提出了“平衡指令难度”策略，其用大模型的困 惑度分数来估算指令数据的难度水平，删除过于简单或过于困难的指令数据，从 而缓解大模型训练不稳定或者过拟合的现象。

### 该部分总结
- 指令的质量比数量更为重要。指令微调中应当有限在使用人工标注的多样性指令数据

-----------------

## 指令微调的作用

#### 整体任务性能改进
- 目标：使用人工构建的指令数据对大模型进行进一步训练，从而增强或者解锁大语言模型的能力。
- 与预训练相比，指令微调的成本显著降低，大模型所需的指令数据量仅为预训练阶段的约万分之一甚至更少
- 经过指令微调的小模型甚至能在性能上超过未进行微调的大模型，且指令微调在不同的模型架构上都能取得相对稳定的增益。
#### 任务求解能力增强
- 主要目标是指导模型理解自然语言指令，并根据此完成相应任务。
- 经过微调的大模型将获得更好的指令遵循能力以及任务求解能力

#### 领域专业化适配
- 在实际应用中，可以针 对大语言模型进行面向特定领域的指令微调，从而使之能够适配下游的任务
- 令微调为大模 型提供了一种通用的领域适配方法，拓宽了它们在实际场景中的应用范围

----------

# 指令微调的训练策略

训练方式：指令微调与预训练较为相似，很多设置包括数据组织形式都可以使用预训练阶段所采用的技术。

## 优化设置
- 指令微调中的优化器设置（AdamW 或 Adafactor）、稳定训练技巧（权重衰减 和梯度裁剪）和训练技术（3D 并行、ZeRO 和混合精度训练）都与预训练保持阶 段一致，可以完全沿用。笔记中主要介绍不同之处。
- ###### 目标函数：
	指令微调可以被视为一个有监督的训练过程，仅在输出部分计算损失，而不计算输入部分的损失
- ###### 批次大小和学习率：
	考虑到在预训练阶段已经学习到了能够展现较好性能的模型参数，指令微调阶段通常仅需要较小的批次大小和学习率对模型进行小幅调整。
- ###### 多轮对话数据的高效训练：
	为了提升训练效率，可以采用特殊的 掩码机制来实现多轮对话数据的高效训练。在因果解码器架构中，由于输入输出 没有明显的分界，可以将所有一个对话的多轮内容一次性输入模型，通过设计损 失掩码来实现仅针对每轮对话的模型输出部分进行损失计算，从而显著减少重复 前缀计算的开销。

### 数据组织策略
- 平衡数据分布：采用样本比例混合策略，混合多个多个指令数据集，从混合数据集中等概率采样每个实例，混合比例的优化也可以带来相应的性能提升
- 多阶段指令数据微调：对于不同阶段的微调，采用不同的微调指令数据，例如在不同微调阶段，训练中可以逐渐增加指令难度和复杂性，从而提升大模型遵循复杂指令的能力。

### 结合预训练数据与指令微调数据
- 为了使得微调过程更加有效和稳定，可以在指令微调期间引入了预训练数据 和任务，这可以看作是对于指令微调的正则化
- MiniCPM [72] 提出在预训练 阶段和指令微调阶段之间添加一个“退火阶段”，该阶段混合使用高质量的预训练 数据和指令微调数据，其实验结果表明该策略优于先预训练再指令微调的两阶段策略

------------

# 参数高效的模型微调
- 目标：减少需要训练的模型参数量

### 低秩适配微调方法
- ##### LoRA 基础：
	为解决参数矩阵过参数化（Over-parametrized）问题，LoRA提出在预训练模型的参数矩阵上添加低秩分解矩阵来近似每层的 148 7.3 参数高效的模型微调 参数更新，从而减少适配下游任务所需要训练的参数
	
	通常的更新过程：
$$
	 W = W_0+\Delta W 
$$
$$
	设原始矩阵为  W_0 \in \mathbb{R}^{H \times H} ，通过低秩分解矩阵  A \in \mathbb{R}^{H \times R} 和  B \in \mathbb{R}^{H \times R} 
$$
$$
来近似参数更新矩阵\Delta W = A \cdot B^T ，其中  R \ll H  是减小后的秩。
$$
	则计算中间状态的公式修改为：
$$
h = W_0 \cdot x + A \cdot B^T \cdot x 
$$
	最终输出结果为：
$$
 W = W_0 + A \cdot B^T 
$$
	简单而言，就是将原本需要更新高维矩阵W的任务转变为对两个低维矩阵A、B的更新以增加效率

### 适配器微调
- 适配器微调（Adapter Tuning）在 Transformer 模型中引入了小型神经网络模块 （称为适配器）
- 操作：首先将原始的特征向量压缩到较低维度，然后使用激活函数进行非线性变换，最后 再将其恢复到原始维度，可以通过相应公式进行表达：
$$
	 h = h+\sigma(h \cdot W^d) \cdot W^u ， 其中  W^d \in \mathbb{R}^{H \times R} ， W^u \in \mathbb{R}^{R \times H} ，且  R \ll H 
$$
- 通常来说，适配器模块将会被集成到 Transformer 架构的每一层中，使用串行的方式分别插入在多头注意力层和前馈网 络层之后、层归一化之前。在微调过程中，适配器模块将根据特定的任务目标进行优化，而原始的语言模型参数在这个过程中保持不变。通过这种方式，可以在微调过程中有效减少需要训练参数的数量。

### 前缀微调
- 操作：在语言模型的每个多头注意力层中都添加了一 组前缀参数，这些前缀参数组成了一个可训练的连续矩阵，可以视为若干虚拟词元的嵌入向量，它们会根据特定任务进行学习。在前缀微调过程中，整个模型中只有前缀参数会被训练，因此可以实现参数高效的模型优化。
	![[Pasted image 20250401235448.png]]

### 提示微调
- 操作：与前缀微调不同，提示微调仅在输入嵌入层中加入可训练的提示向量，在离散提示方法的基础上，提示微调首先在输入文本端插入一组连续嵌入数值的提示词元，这些提示词元可以以自由形式或前缀形式来增强输入文本，用于解决特定的下游任务。在具体实现中，只需要 将可学习的特定任务提示向量与输入文本向量结合起来一起输入到语言模型中。
	![[Pasted image 20250401235919.png]]

--------
